{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações iniciais\n",
    "\n",
    "Para fazer um stacking de qualidade, precisamos que nossos modelos tenham diversidade entre si, ou seja, utilizando vários parâmetros devemos fazer eles serem diferentes. Neste projeto, irei utilizar a otimização bayesian optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalhe: todos os algoritmos foram executados e suas previsões salvas para utilizações nos próximos notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib as jb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from skopt import gp_minimize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura e separação das bases em X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lvl0 = pd.read_csv('train_lvl0.csv')\n",
    "train_lvl1 = pd.read_csv('train_lvl1.csv')\n",
    "val = pd.read_csv(\"valid.csv\")\n",
    "\n",
    "X_train0, Y_train0 = train_lvl0.drop(columns=['Date','Sales']), train_lvl0['Sales']\n",
    "X_train1, Y_train1 = train_lvl1.drop(columns=['Date','Sales']), train_lvl1['Sales']\n",
    "X_val, Y_val = val.drop(columns=['Date','Sales']), val['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tune_lgbm(params):\n",
    "    num_leaves, min_data_in_leaf, learning_rate,n_estimators = params\n",
    "    mdl = LGBMRegressor(num_leaves=num_leaves,\n",
    "                        min_data_in_leaf=min_data_in_leaf,\n",
    "                        learning_rate=learning_rate, \n",
    "                        n_estimators=n_estimators,\n",
    "                        random_state=0)\n",
    "    mdl.fit(X_train0, Y_train0)\n",
    "    \n",
    "    p = mdl.predict(X_train1)\n",
    "    model_name_train1 = \"./preds_train1/lgbm_{}_{}_{}_{}.pkl.z\".format(num_leaves, min_data_in_leaf, learning_rate,n_estimators) \n",
    "    jb.dump(p, model_name_train1)\n",
    "    #Salvando previsões do train1\n",
    "    \n",
    "    metric = np.sqrt(mean_squared_error(Y_train1,p))\n",
    "    \n",
    "    p = mdl.predict(X_val)\n",
    "    model_name_val1 = \"./preds_val/lgbm_{}_{}_{}_{}.pkl.z\".format(num_leaves, min_data_in_leaf, learning_rate,n_estimators) \n",
    "    jb.dump(p, model_name_val1)\n",
    "    #Salvando previsões do val1\n",
    "    print(params, metric)\n",
    "    print()\n",
    "    \n",
    "    return metric\n",
    "\n",
    "space = [(2, 500),#num_leaves\n",
    "         (1, 100),#min_data_in_leaf\n",
    "         (1e-4, 1e-1),#learning_rate\n",
    "        (50,150)]#n_estimators\n",
    "\n",
    "res = gp_minimize(tune_lgbm, space, random_state=0, verbose=0, n_calls=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tune_rf(params):\n",
    "    n_estimators,max_depth,min_samples_leaf = params\n",
    "    mdl = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                               max_depth=max_depth,\n",
    "                               min_samples_leaf=min_samples_leaf,\n",
    "                               n_jobs=-1)\n",
    "    \n",
    "    mdl.fit(X_train0, Y_train0)\n",
    "    p = mdl.predict(X_train1)\n",
    "    model_name_train1 = \"./preds_train1/rf_{}_{}_{}.pkl.z\".format(n_estimators, max_depth, min_samples_leaf) \n",
    "    jb.dump(p, model_name_train1)\n",
    "    #Salvando previsões do train1\n",
    "    \n",
    "    metric = np.sqrt(mean_squared_error(Y_train1,p))\n",
    "    \n",
    "    p = mdl.predict(X_val)\n",
    "    model_name_val1 = \"./preds_val/rf_{}_{}_{}.pkl.z\".format(n_estimators, max_depth, min_samples_leaf)\n",
    "    jb.dump(p, model_name_val1)\n",
    "    #Salvando previsões do val1\n",
    "    \n",
    "    print(params, metric)\n",
    "    print()\n",
    "    return metric\n",
    "space = [(100, 200),#n_estimators\n",
    "         (1, 20),#max_depth\n",
    "         (1, 100)]#min_samples_leaf\n",
    "\n",
    "res = gp_minimize(tune_rf, space, random_state=0, verbose=0, n_calls=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tune_knn(params):\n",
    "    n_neighbors,metric = params\n",
    "    mdl = KNeighborsRegressor(n_neighbors=n_neighbors,\n",
    "                              metric=metric,\n",
    "                              n_jobs=-1)\n",
    "    \n",
    "    mdl.fit(X_train0, Y_train0)\n",
    "    p = mdl.predict(X_train1)\n",
    "    model_name_train1 = \"./preds_train1/knn_{}_{}.pkl.z\".format(n_neighbors, metric) \n",
    "    jb.dump(p, model_name_train1)\n",
    "    #Salvando previsões do train1\n",
    "    metric2 = np.sqrt(mean_squared_error(Y_train1,p))\n",
    "    \n",
    "    p = mdl.predict(X_val)\n",
    "    model_name_val1 = \"./preds_val/knn_{}_{}.pkl.z\".format(n_neighbors, metric) \n",
    "    jb.dump(p, model_name_val1)\n",
    "    #Salvando previsões do val1\n",
    "    print(params, metric2)\n",
    "    print()\n",
    "    return metric2\n",
    "\n",
    "space = [(1, 50),#n_neighbors\n",
    "         ['euclidean','manhattan','chebyshev','minkowski']]#metric\n",
    "\n",
    "res = gp_minimize(tune_knn, space, random_state=0, verbose=0, n_calls=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tune_svm(params):\n",
    "    kernel,C = params\n",
    "    mdl = SVR(kernel=kernel,\n",
    "            C=C)\n",
    "    \n",
    "    mdl.fit(X_train0, Y_train0)\n",
    "    p = mdl.predict(X_train1)\n",
    "    model_name_train1 = \"./preds_train1/svm_{}_{}.pkl.z\".format(kernel, C) \n",
    "    jb.dump(p, model_name_train1)\n",
    "    #Salvando previsões do train1\n",
    "    metric = np.sqrt(mean_squared_error(Y_train1,p))\n",
    "    \n",
    "    p = mdl.predict(X_val)\n",
    "    model_name_val1 = \"./preds_val/svm_{}_{}.pkl.z\".format(kernel, C)\n",
    "    jb.dump(p, model_name_val1)\n",
    "    #Salvando previsões do val1\n",
    "    \n",
    "    print(params, metric)\n",
    "    print()\n",
    "    return metric\n",
    "space = [['sigmoid','rbf'#kernel\n",
    "         ],\n",
    "         (0.1,10)]#c\n",
    "\n",
    "res = gp_minimize(tune_svm, space, random_state=0, verbose=0, n_calls=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicando o funcionamento da otimização:\n",
    "No space temos os parâmetros a serem tunados definidos em intervalos (1,10) significa que as otimizações irão de 1 a 10, 1 2 3 4 5 6 7 8 9 10, porém de forma diferente do grid search, não é um algoritmo de força bruta.\n",
    "\n",
    "De forma análoga para as categóricas, 'sigmoid','rbf', serão testadas uma de cada vez."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
