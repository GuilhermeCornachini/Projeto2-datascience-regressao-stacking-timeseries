{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações iniciais\n",
    "Conforme feito nos notebooks anterios, nós preparamos os dados, geramos diversidades, e selecionamos as melhores combinações de modelos. Agora iremos apenas ajustar os modelos e persistir na memória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura e separação das bases em X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lvl0 = pd.read_csv('train_lvl0.csv')\n",
    "train_lvl1 = pd.read_csv('train_lvl1.csv')\n",
    "val = pd.read_csv(\"valid.csv\")\n",
    "\n",
    "X_train0, Y_train0 = train_lvl0.drop(columns=['Date','Sales']), train_lvl0['Sales']\n",
    "X_train1, Y_train1 = train_lvl1.drop(columns=['Date','Sales']), train_lvl1['Sales']\n",
    "X_val, Y_val = val.drop(columns=['Date','Sales']), val['Sales']\n",
    "\n",
    "preds_lvl1 = pd.DataFrame()\n",
    "preds_val = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando uma lista com os modelos\n",
    "Copiando os parâmetros dos modelos selecionados no notebook anterior, criamos uma lista com cada modelo, para assim facilitar na implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "        LGBMRegressor(num_leaves=110,\n",
    "                        min_data_in_leaf=14,\n",
    "                        learning_rate=0.03248168667854209, \n",
    "                        n_estimators=215,\n",
    "                        random_state=0),\n",
    "    \n",
    "        LGBMRegressor(num_leaves=361,\n",
    "                        min_data_in_leaf=59,\n",
    "                        learning_rate=0.05378358562195618, \n",
    "                        n_estimators=276,\n",
    "                        random_state=0),\n",
    "\n",
    "        RandomForestRegressor(n_estimators=176,\n",
    "                                       max_depth=3,\n",
    "                                       min_samples_leaf=48,\n",
    "                                       n_jobs=-1),\n",
    "    \n",
    "        LGBMRegressor(num_leaves=24,\n",
    "                        min_data_in_leaf=1,\n",
    "                        learning_rate=0.03199227519485914, \n",
    "                        n_estimators=200,\n",
    "                        random_state=0),\n",
    "    \n",
    "        LGBMRegressor(num_leaves=185,\n",
    "                        min_data_in_leaf=96,\n",
    "                        learning_rate=0.014121042963223253, \n",
    "                        n_estimators=287,\n",
    "                        random_state=0),\n",
    "\n",
    "        SVR(kernel='rbf',\n",
    "        C=0.6614584754426877),\n",
    "\n",
    "        SVR(kernel='rbf',\n",
    "        C=8.713863857748523),\n",
    "    \n",
    "        LGBMRegressor(num_leaves=238,\n",
    "                        min_data_in_leaf=80,\n",
    "                        learning_rate=0.05209570020716538, \n",
    "                        n_estimators=268,\n",
    "                        random_state=0),\n",
    "    \n",
    "        LGBMRegressor(num_leaves=427,\n",
    "                        min_data_in_leaf=1,\n",
    "                        learning_rate=0.0001, \n",
    "                        n_estimators=236,\n",
    "                        random_state=0),\n",
    "    \n",
    "        RandomForestRegressor(n_estimators=139,\n",
    "                                   max_depth=17,\n",
    "                                   min_samples_leaf=34,\n",
    "                                   n_jobs=-1),\n",
    "        LGBMRegressor(num_leaves=55,\n",
    "                    min_data_in_leaf=48,\n",
    "                    learning_rate=0.018714601098343324, \n",
    "                    n_estimators=274,\n",
    "                    random_state=0),\n",
    "    \n",
    "      \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento dos modelos \n",
    "Utilizando umá estrutura de repetição, treinamos cada modelo com base em sua posição na lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    models[i].fit(X_train0, Y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando as previsões de primeiro nivel e da validação \n",
    "Novamente, percorrendo com uma estrutura de repetição, com base na posição de cada modelo na lista, faço a previsões de cada modelo, e os guardo em dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    prev = models[i].predict(X_train1)\n",
    "    preds_lvl1['Modelo_{}'.format(i)] = prev\n",
    "\n",
    "    prev = models[i].predict(X_val)\n",
    "    preds_val['Modelo_{}'.format(i)] = prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a ridge de 2º nível"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme feito no notebook anterior, utilizamos uma ridge no nosso segundo nível, que irá utilizar as previsões dos modelos acima como features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "ridge.fit(preds_lvl1,Y_train1)\n",
    "preds = ridge.predict(preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385.98652981196255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(Y_val,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme vemos, nossa baseline no primeiro nobeook para a validação era cerca de 3866, que eram as vendas utilizadas no dia anterior. E apesar de todo trabalho para chegar até aqui, conseguimos a marca de 385."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando as previsões da ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5716.12732818,  6570.02509147, 10433.63918445, 11727.46530209,\n",
       "        6671.86054738,  6675.36377111, 12331.55182077,  8121.65913626,\n",
       "        9814.75402386,  7152.67584754,  8648.77276758,  9632.80598566,\n",
       "        5291.70927796,  7016.89290764,  7446.96659215,  9832.0580813 ,\n",
       "        9014.23640848,  7743.35808883,  8807.28857458, 10132.21079557,\n",
       "        5842.35513923,  6832.95705613,  9857.41420906, 10806.29990296,\n",
       "        6099.87289615,  6094.03756252,  9617.84749769,  7127.52382161,\n",
       "        9686.33752851,  6452.61366789,  9352.81101154,  9710.80865792,\n",
       "        6248.08804743,  7586.19155834,  7989.13964037,  9954.74646691,\n",
       "        7824.91690016,  7854.65496018,  9673.98846101, 10386.9469018 ,\n",
       "          32.00237652,  5929.0089488 ,   150.23750718, 10351.41011626,\n",
       "        5634.42297906,  5661.34877867,  9816.59050748,  8991.84181069,\n",
       "          21.60475997,  6282.19409116,  8810.22986694,  8674.87227977,\n",
       "          40.6944794 ,    31.0558333 ,  7717.44898145,    52.71631976,\n",
       "        8229.667697  ,  7600.91626258,    21.66801758,    25.43412686,\n",
       "        5574.27402557,  4801.66083654,  9464.83288863, 11282.05149159,\n",
       "        5287.37411678,  5635.24856819, 10298.95729491,  6411.77569497,\n",
       "        9882.02542771,  6267.18275471,  8408.2815468 ,  8185.61295326,\n",
       "        6194.93773825,  7338.50037457,  7663.76713068,  9950.43041718,\n",
       "        7164.07591922,  7950.08697732,  9193.54932192,  8099.90668283,\n",
       "        3961.6614168 ,  2645.47051569,  4913.2070585 ,  8924.22431795,\n",
       "        2056.01410001,  2945.78836375,  6371.06296162,  3622.23467223,\n",
       "        7014.87627186,  5035.29150853,  5602.16592203,  6100.36514808,\n",
       "        3744.77906295,  3810.78121443,  6655.43170357,  5346.60140198,\n",
       "        2652.45606992,  4696.27323836,  4735.5477806 ,  5363.55521342])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsões na base de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como essa é uma base retirada e adaptada de uma competição do kaggle, temos uma base de teste, porém os resultados não são 100% aplicáveis, pois reduzimos o número de lojas. Se baseando nesse contexto, conforme feito no notebook 1, faremos a previsão para apenas as 20 primeiras lojas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>40242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>40243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>40244</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>40245</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>40246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Sales\n",
       "0        1      0\n",
       "1        2    133\n",
       "2        3     14\n",
       "3        4      0\n",
       "4        5      5\n",
       "..     ...    ...\n",
       "667  40242      0\n",
       "668  40243      0\n",
       "669  40244     11\n",
       "670  40245     15\n",
       "671  40246      0\n",
       "\n",
       "[672 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('teste.csv')\n",
    "Sub = pd.DataFrame()\n",
    "Sub['Id'] = test['Id']\n",
    "test = test.drop(columns=['Date','Id'])\n",
    "\n",
    "preds_test = pd.DataFrame()\n",
    "\n",
    "for i in range(len(models)):\n",
    "    prev = models[i].predict(test)\n",
    "    preds_test['Modelo_{}'.format(i)] = prev\n",
    "\n",
    "p = ridge.predict(preds_test)\n",
    "p[p < 0] = 0\n",
    "Sub['Sales'] = p.round().astype(int)\n",
    "Sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistindo na memória os modelos para utilizações em caso de deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é uma parte muito importante em caso de deploy, pois precisamos salvar os modelos para que possam ser utilizados no futuro em produção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Modelos.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pkl.dump([models,ridge], open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos modelos para certeza de que não houve problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBMRegressor(learning_rate=0.03248168667854209, min_data_in_leaf=14,\n",
      "              n_estimators=215, num_leaves=110, random_state=0), LGBMRegressor(learning_rate=0.05378358562195618, min_data_in_leaf=59,\n",
      "              n_estimators=276, num_leaves=361, random_state=0), RandomForestRegressor(max_depth=3, min_samples_leaf=48, n_estimators=176,\n",
      "                      n_jobs=-1), LGBMRegressor(learning_rate=0.03199227519485914, min_data_in_leaf=1,\n",
      "              n_estimators=200, num_leaves=24, random_state=0), LGBMRegressor(learning_rate=0.014121042963223253, min_data_in_leaf=96,\n",
      "              n_estimators=287, num_leaves=185, random_state=0), SVR(C=0.6614584754426877), SVR(C=8.713863857748523), LGBMRegressor(learning_rate=0.05209570020716538, min_data_in_leaf=80,\n",
      "              n_estimators=268, num_leaves=238, random_state=0), LGBMRegressor(learning_rate=0.0001, min_data_in_leaf=1, n_estimators=236,\n",
      "              num_leaves=427, random_state=0), RandomForestRegressor(max_depth=17, min_samples_leaf=34, n_estimators=139,\n",
      "                      n_jobs=-1), LGBMRegressor(learning_rate=0.018714601098343324, min_data_in_leaf=48,\n",
      "              n_estimators=274, num_leaves=55, random_state=0)] Ridge()\n"
     ]
    }
   ],
   "source": [
    "open_file = open(file_name, \"rb\")\n",
    "models,ridge = pkl.load(open_file)\n",
    "\n",
    "print(models,ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações finais \n",
    "\n",
    "Estou utilizando esses notebooks como forma de demonstrar minhas habilidades que venho adquirindo ao longo dessa minha trajetória como estudante de engenharia de computação e cientista de dados.\n",
    "\n",
    "Agradeço a você que tenha acompanhado esse projeto até aqui. Como ideia para futuros projetos pode ser interessante recriar com todas as lojas disponíveis no dataset original e não apenas 20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
